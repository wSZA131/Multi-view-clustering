# 假设 batch_size=4, class_num=3
q_i = torch.tensor([
    [0.7, 0.2, 0.1],  # 样本1: 70%概率属于类别0, 20%类别1, 10%类别2
    [0.1, 0.8, 0.1],  # 样本2: 10%概率属于类别0, 80%类别1, 10%类别2
    [0.3, 0.3, 0.4],  # 样本3: 30%概率属于类别0, 30%类别1, 40%类别2
    [0.2, 0.5, 0.3]   # 样本4: 20%概率属于类别0, 50%类别1, 30%类别2
])
print("q_i shape:", q_i.shape)  # torch.Size([4, 3])

---------------------------------------------------------------------------
p_i = q_i.sum(0).view(-1) #按列求和并且是成一维格式
---------------------------------------------------------------------------
p_i /= p_i.sum()#计算并归一化
######################################################
total = p_i.sum()  # 1.3 + 1.8 + 0.9 = 4.0
p_i_normalized = p_i / total
print("归一化后 p_i:", p_i_normalized)  # tensor([0.325, 0.450, 0.225])
#######################################################
归一化可以表示每个类别的经验概率分布，反应模型预测的类别分布，避免平凡解
